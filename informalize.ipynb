{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b531852-74bb-41ae-beef-f3d5b231ed04",
   "metadata": {},
   "source": [
    "### Informalize\n",
    "\n",
    "1. Select a random sample of the lean and isabelle data.\n",
    "2. Query gpt-4 using the OpenAI API\n",
    "3. Save the outputs to the /data/informalize folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f9f02c-4979-4630-a439-09c7738103b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "SAMPLE_SIZE = 2\n",
    "SEED = 11632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb2cedd3-5ac1-4406-8074-2fb995935d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = pd.read_json(open(\"data/modified_mma/isabelle_train.jsonl\",\"r\"), lines = True).sample(SAMPLE_SIZE, random_state = SEED)\n",
    "df_l = pd.read_json(open(\"data/modified_mma/lean_train.jsonl\",\"r\"), lines = True).sample(SAMPLE_SIZE,random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c742c0b-4ef8-43d2-ae7d-cfc7627946b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=\"STRING\"\n",
    "  base_url=\"STRING\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b40d4172-ad1a-4417-94c4-861dbd3626a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:13,  6.97s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert output_both, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tl/jby6b3xs1nlc_7v9ps7zfv6c0000gn/T/ipykernel_70171/573375226.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m     \u001b[0moutput_both\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdf_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"output_both\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_both\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mdf_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"output_statement\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_statement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mdf_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"output_name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5154\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m             )\n\u001b[1;32m   5156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5157\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5158\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {column}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5161\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert output_both, already exists"
     ]
    }
   ],
   "source": [
    "output_name = []\n",
    "output_statement = []\n",
    "output_both = []\n",
    "from tqdm import tqdm \n",
    "for index, row in tqdm(df_i.iterrows()):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages = [{\"role\":\"user\",\"content\":row[\"prompt_name\"]}],\n",
    "        max_tokens = 512,\n",
    "        n=1\n",
    "    )\n",
    "    output_name.append(completion.choices[0].message.content)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages = [{\"role\":\"user\",\"content\":row[\"prompt_statement\"]}],\n",
    "        max_tokens = 512,\n",
    "        n=1\n",
    "    )\n",
    "\n",
    "    output_statement.append(completion.choices[0].message.content)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model =\"gpt-4o\",\n",
    "        messages = [{\"role\":\"user\",\"content\":row[\"prompt_both\"]}],\n",
    "        max_tokens = 512,\n",
    "        n=1\n",
    "    )\n",
    "    output_both.append(completion.choices[0].message.content)\n",
    "    \n",
    "df_i.insert(0,\"output_both\",output_both)\n",
    "df_i.insert(0,\"output_statement\",output_statement)\n",
    "df_i.insert(0,\"output_name\",output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94873ac2-7ad4-4a7c-9e28-96a99c8eb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l.to_csv(f\"data/informalizations/isabelle_{SAMPLE_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbc77290-7906-4143-9e5e-e0fcec1cd67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=\"sk-3AoIomsIRrEs37k4d5aRQA\",\n",
    "  base_url=\"https://cmu.litellm.ai\",\n",
    ")\n",
    "output_name = []\n",
    "output_statement = []\n",
    "output_both = []\n",
    "for index, row in df_l.iterrows():\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages = [{\"role\":\"user\",\"content\":row[\"prompt_name\"]}],\n",
    "        max_tokens = 512,\n",
    "        n=1\n",
    "    )\n",
    "    output_name.append(completion.choices[0].message.content)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages = [{\"role\":\"user\",\"content\":row[\"prompt_statement\"]}],\n",
    "        max_tokens = 512,\n",
    "        n=1\n",
    "    )\n",
    "\n",
    "    output_statement.append(completion.choices[0].message.content)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model =\"gpt-4o\",\n",
    "        messages = [{\"role\":\"user\",\"content\":row[\"prompt_both\"]}],\n",
    "        max_tokens = 512,\n",
    "        n=1\n",
    "    )\n",
    "    output_both.append(completion.choices[0].message.content)\n",
    "    if index in [200,400,600,800,1000,1200,1400,1600,1800]:\n",
    "        pd.DataFrame({\"output_both\":output_both,\"output_statemet\":output_statement, \"output_name\":output_name}).to_json(\"lean_running\")\n",
    "df_l.insert(0,\"output_both\",output_both)\n",
    "df_l.insert(0,\"output_statement\",output_statement)\n",
    "df_l.insert(0,\"output_name\",output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e5bec09-61b9-4318-a02b-dbff18428a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l.to_csv(f\"data/informalizations/lean_{SAMPLE_SIZE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
