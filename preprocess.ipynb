{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866f4405-37bd-477f-a402-141e58d4d356",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "\n",
    "1. Load the data from mmadata.zip.\n",
    "2. Extract the statement and name.\n",
    "3. Add the prompts to be used with the gpt-4 api.\n",
    "4. Save the outputs to the /data/modified folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ddfa9f-45bb-453e-839f-3f50f0f751ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb892e6-f350-4d3e-8d92-cfc8a0db5601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/lean_test.jsonl has been refined to 1927 records from 1927\n",
      "data/isabelle_train.jsonl has been refined to 243173 records from 243214\n",
      "data/isabelle_val.jsonl has been refined to 1023 records from 1024\n",
      "data/lean_val.jsonl has been refined to 1930 records from 1930\n",
      "data/lean_train.jsonl has been refined to 84679 records from 84679\n"
     ]
    }
   ],
   "source": [
    "# modify the files to change the inputs as expected. \n",
    "# This is not deep, but we choose to do it on the system. \n",
    "# Negligible lag on my laptop. \n",
    "with zipfile.ZipFile(\"data.zip\") as zip_dir:\n",
    "    files = [file for file in zip_dir.namelist() if 'jsonl' in file and not \"MACOS\" in file]\n",
    "    for file in files:\n",
    "        zip_dir.extract(file)\n",
    "        \n",
    "for file in files:\n",
    "    df = pd.read_json(file, lines=True)\n",
    "    df[\"input\"] = df[\"input\"].apply(lambda x: x.split(\"\\n\")[1])\n",
    "    df[\"theorem_name\"] = df[\"output\"].apply(lambda x: ' '.join(x.split(\" \")[0:2]))\n",
    "    df[\"theorem_statement\"] = df[\"output\"].apply(lambda x: ' '.join(x.split(\" \")[2:]))\n",
    "    df[\"language\"] = file.split(\"/\")[1].split(\"_\")[0].capitalize()\n",
    "    df[\"prompt_name\"] = df.apply(lambda row: f\"{row.language} {row.theorem_name} Translate the theorem name in {row.language} to natural language.\", axis = 1)\n",
    "    df[\"prompt_statement\"] = df.apply(lambda row: f\"{row.language} {row.theorem_statement} Translate the theorem statement in {row.language} to natural language.\", axis = 1)\n",
    "    df[\"prompt_both\"] = df.apply(lambda row: f\"{row.language} {row.output} Translate the theorem in {row.language} to natural language.\", axis = 1)\n",
    "    #print(df.iloc[0][\"language\"])\n",
    "    old_shape = df.shape[0]\n",
    "    df = df[df[\"output\"] == df[\"theorem_name\"] + \" \" + df[\"theorem_statement\"]]\n",
    "    print(f\"{file} has been refined to {df.shape[0]} records from {old_shape}\")\n",
    "    df.to_json(\"data/modified_mma/\"+file[4:], orient=\"records\",lines=True)\n",
    "    os.remove(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae54c5da-f4bc-46e9-9c5d-a180b309978f",
   "metadata": {},
   "source": [
    "We removed some data because it did not contain statements and was hence unsuitable for our experiment. As the numbers above show, we only removed 42 records this way, all from Isabelle. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
